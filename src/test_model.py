"""
–¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –Ω–∞–≤—á–µ–Ω–æ—ó –º–æ–¥–µ–ª—ñ
–û—Ü—ñ–Ω–∫–∞ –º–µ—Ç—Ä–∏–∫: Accuracy, Latency, —Ä–æ–∑–º—ñ—Ä –º–æ–¥–µ–ª—ñ
"""

import torch
import torch.nn.functional as F
import time
import os
import sys
import numpy as np
from collections import Counter

# –î–æ–¥–∞—î–º–æ —à–ª—è—Ö –¥–æ –º–æ–¥—É–ª—ñ–≤
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from src.model import SimpleCNN, EvenSimplerCNN
from src.simple_data_loader import create_simple_data_loaders

class ModelTester:
    """–ö–ª–∞—Å –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ"""
    
    def __init__(self, model, model_path=None):
        self.model = model
        self.device = torch.device('cpu')
        self.classes = ['yes', 'no', 'up', 'down']
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –≤–∞–≥–∏ —è–∫—â–æ —î
        if model_path and os.path.exists(model_path):
            self.model.load_state_dict(torch.load(model_path, map_location=self.device))
            print(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –º–æ–¥–µ–ª—å –∑ {model_path}")
        else:
            print(f"‚ö†Ô∏è –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –Ω–µ–Ω–∞—á–µ–Ω—É –º–æ–¥–µ–ª—å")
            
        self.model.to(self.device)
        self.model.eval()
    
    def calculate_model_size(self):
        """–û–±—á–∏—Å–ª—é—î–º–æ —Ä–æ–∑–º—ñ—Ä –º–æ–¥–µ–ª—ñ"""
        total_params = sum(p.numel() for p in self.model.parameters())
        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
        
        # –†–æ–∑–º—ñ—Ä —É –±–∞–π—Ç–∞—Ö (float32 = 4 –±–∞–π—Ç–∏ –Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä)
        size_bytes = total_params * 4
        size_kb = size_bytes / 1024
        size_mb = size_kb / 1024
        
        return {
            "total_params": total_params,
            "trainable_params": trainable_params,
            "size_bytes": size_bytes,
            "size_kb": size_kb,
            "size_mb": size_mb
        }
    
    def measure_latency(self, test_loader, num_samples=100):
        """–í–∏–º—ñ—Ä—é—î–º–æ –ª–∞—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—å (—á–∞—Å —ñ–Ω—Ñ–µ—Ä–µ–Ω—Å—É)"""
        print(f"‚è±Ô∏è –í–∏–º—ñ—Ä—é—î–º–æ –ª–∞—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—å –Ω–∞ {num_samples} –∑—Ä–∞–∑–∫–∞—Ö...")
        
        # –ë–µ—Ä–µ–º–æ —Ç–µ—Å—Ç–æ–≤—ñ –¥–∞–Ω—ñ
        all_times = []
        sample_count = 0
        
        with torch.no_grad():
            for batch_data, _ in test_loader:
                batch_data = batch_data.to(self.device)
                
                # –¢–µ—Å—Ç—É—î–º–æ –∫–æ–∂–µ–Ω –∑—Ä–∞–∑–æ–∫ —É –±–∞—Ç—á—ñ –æ–∫—Ä–µ–º–æ
                for i in range(batch_data.size(0)):
                    if sample_count >= num_samples:
                        break
                        
                    single_sample = batch_data[i:i+1]  # [1, 1, 64, 32]
                    
                    # –í–∏–º—ñ—Ä—é—î–º–æ —á–∞—Å
                    start_time = time.time()
                    output = self.model(single_sample)
                    end_time = time.time()
                    
                    inference_time = (end_time - start_time) * 1000  # –º—ñ–ª—ñ—Å–µ–∫—É–Ω–¥–∏
                    all_times.append(inference_time)
                    sample_count += 1
                
                if sample_count >= num_samples:
                    break
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        avg_latency = np.mean(all_times)
        median_latency = np.median(all_times)
        min_latency = np.min(all_times)
        max_latency = np.max(all_times)
        std_latency = np.std(all_times)
        
        return {
            "average_ms": avg_latency,
            "median_ms": median_latency,
            "min_ms": min_latency,
            "max_ms": max_latency,
            "std_ms": std_latency,
            "samples_tested": len(all_times)
        }
    
    def evaluate_accuracy(self, test_loader):
        """–î–µ—Ç–∞–ª—å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç—ñ"""
        print(f"üéØ –û—Ü—ñ–Ω—é—î–º–æ —Ç–æ—á–Ω—ñ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º—É –Ω–∞–±–æ—Ä—ñ...")
        
        all_predictions = []
        all_targets = []
        class_correct = [0] * len(self.classes)
        class_total = [0] * len(self.classes)
        
        total_correct = 0
        total_samples = 0
        
        with torch.no_grad():
            for data, targets in test_loader:
                data, targets = data.to(self.device), targets.to(self.device)
                
                outputs = self.model(data)
                _, predicted = torch.max(outputs, 1)
                
                # –ó–∞–≥–∞–ª—å–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                total_samples += targets.size(0)
                total_correct += (predicted == targets).sum().item()
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–ª–∞—Å–∞—Ö
                for i in range(len(targets)):
                    target_class = targets[i].item()
                    predicted_class = predicted[i].item()
                    
                    class_total[target_class] += 1
                    if target_class == predicted_class:
                        class_correct[target_class] += 1
                    
                    all_predictions.append(predicted_class)
                    all_targets.append(target_class)
        
        # –ó–∞–≥–∞–ª—å–Ω–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å
        overall_accuracy = 100.0 * total_correct / total_samples
        
        # –¢–æ—á–Ω—ñ—Å—Ç—å –ø–æ –∫–ª–∞—Å–∞—Ö
        class_accuracies = {}
        for i, class_name in enumerate(self.classes):
            if class_total[i] > 0:
                acc = 100.0 * class_correct[i] / class_total[i]
                class_accuracies[class_name] = {
                    "accuracy": acc,
                    "correct": class_correct[i],
                    "total": class_total[i]
                }
            else:
                class_accuracies[class_name] = {
                    "accuracy": 0.0,
                    "correct": 0,
                    "total": 0
                }
        
        # –ú–∞—Ç—Ä–∏—Ü—è –ø–ª—É—Ç–∞–Ω–∏–Ω–∏ (confusion matrix)
        confusion_matrix = np.zeros((len(self.classes), len(self.classes)), dtype=int)
        for true_label, pred_label in zip(all_targets, all_predictions):
            confusion_matrix[true_label][pred_label] += 1
        
        return {
            "overall_accuracy": overall_accuracy,
            "class_accuracies": class_accuracies,
            "confusion_matrix": confusion_matrix.tolist(),
            "total_samples": total_samples,
            "total_correct": total_correct
        }
    
    def run_full_evaluation(self, test_loader):
        """–ü–æ–≤–Ω–∞ –æ—Ü—ñ–Ω–∫–∞ –º–æ–¥–µ–ª—ñ"""
        print("üîç –ó–∞–ø—É—Å–∫–∞—î–º–æ –ø–æ–≤–Ω—É –æ—Ü—ñ–Ω–∫—É –º–æ–¥–µ–ª—ñ...")
        print("=" * 50)
        
        # 1. –†–æ–∑–º—ñ—Ä –º–æ–¥–µ–ª—ñ
        size_info = self.calculate_model_size()
        
        # 2. –¢–æ—á–Ω—ñ—Å—Ç—å
        accuracy_info = self.evaluate_accuracy(test_loader)
        
        # 3. –õ–∞—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—å
        latency_info = self.measure_latency(test_loader)
        
        # –ó–≤–æ–¥–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        results = {
            "model_size": size_info,
            "accuracy": accuracy_info,
            "latency": latency_info
        }
        
        return results

def print_results(results):
    """–ö—Ä–∞—Å–∏–≤–æ –≤–∏–≤–æ–¥–∏–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏"""
    print("\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–ò –û–¶–Ü–ù–ö–ò –ú–û–î–ï–õ–Ü")
    print("=" * 50)
    
    # –†–æ–∑–º—ñ—Ä –º–æ–¥–µ–ª—ñ
    size = results["model_size"]
    print(f"üíæ –†–û–ó–ú–Ü–† –ú–û–î–ï–õ–Ü:")
    print(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤: {size['total_params']:,}")
    print(f"   –†–æ–∑–º—ñ—Ä: {size['size_kb']:.1f} KB ({size['size_mb']:.2f} MB)")
    
    # –¢–æ—á–Ω—ñ—Å—Ç—å
    acc = results["accuracy"]
    print(f"\nüéØ –¢–û–ß–ù–Ü–°–¢–¨:")
    print(f"   –ó–∞–≥–∞–ª—å–Ω–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å: {acc['overall_accuracy']:.1f}%")
    print(f"   –ó—Ä–∞–∑–∫—ñ–≤ –ø—Ä–æ—Ç–µ—Å—Ç–æ–≤–∞–Ω–æ: {acc['total_samples']}")
    print(f"   –ü—Ä–∞–≤–∏–ª—å–Ω–∏—Ö –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π: {acc['total_correct']}")
    
    print(f"\nüìà –¢–æ—á–Ω—ñ—Å—Ç—å –ø–æ –∫–ª–∞—Å–∞—Ö:")
    for class_name, class_info in acc["class_accuracies"].items():
        accuracy = class_info["accuracy"]
        correct = class_info["correct"]
        total = class_info["total"]
        print(f"   {class_name:>4}: {accuracy:5.1f}% ({correct:3d}/{total:3d})")
    
    # –õ–∞—Ç–µ–Ω—Ç–Ω—ñ—Å—Ç—å
    lat = results["latency"]
    print(f"\n‚ö° –®–í–ò–î–ö–Ü–°–¢–¨ (LATENCY):")
    print(f"   –°–µ—Ä–µ–¥–Ω—è: {lat['average_ms']:.2f} –º—Å")
    print(f"   –ú–µ–¥—ñ–∞–Ω–∞: {lat['median_ms']:.2f} –º—Å")
    print(f"   –ú—ñ–Ω/–ú–∞–∫—Å: {lat['min_ms']:.2f} / {lat['max_ms']:.2f} –º—Å")
    
    # –ú–∞—Ç—Ä–∏—Ü—è –ø–ª—É—Ç–∞–Ω–∏–Ω–∏
    print(f"\nüîÄ –ú–ê–¢–†–ò–¶–Ø –ü–õ–£–¢–ê–ù–ò–ù–ò:")
    classes = ['yes', 'no', 'up', 'down']
    cm = np.array(acc["confusion_matrix"])
    
    print("      " + "".join(f"{cls:>6}" for cls in classes))
    for i, true_class in enumerate(classes):
        row_str = f"{true_class:>4}: "
        for j in range(len(classes)):
            row_str += f"{cm[i][j]:>6}"
        print(row_str)

def main():
    """–û—Å–Ω–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è"""
    print("üß™ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è Speech Commands –º–æ–¥–µ–ª—ñ")
    print("=" * 50)
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏
    MODEL_TYPE = 'simple'  # –∞–±–æ 'even_simpler'
    MODEL_PATH = f'./models/best_model_{MODEL_TYPE}.pth'
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ —Ç–µ—Å—Ç–æ–≤—ñ –¥–∞–Ω—ñ
    print("üìÇ –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ —Ç–µ—Å—Ç–æ–≤—ñ –¥–∞–Ω—ñ...")
    _, test_loader = create_simple_data_loaders(batch_size=32)
    
    if test_loader is None:
        print("‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö!")
        return
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ –º–æ–¥–µ–ª—å
    print(f"üèóÔ∏è –°—Ç–≤–æ—Ä—é—î–º–æ –º–æ–¥–µ–ª—å: {MODEL_TYPE}")
    if MODEL_TYPE == 'simple':
        model = SimpleCNN(num_classes=4)
    else:
        model = EvenSimplerCNN(num_classes=4)
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ —Ç–µ—Å—Ç–µ—Ä
    tester = ModelTester(model, MODEL_PATH)
    
    # –ó–∞–ø—É—Å–∫–∞—î–º–æ –æ—Ü—ñ–Ω–∫—É
    results = tester.run_full_evaluation(test_loader)
    
    # –í–∏–≤–æ–¥–∏–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
    print_results(results)
    
    # –í–∏—Å–Ω–æ–≤–∫–∏ —Ç–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
    accuracy = results["accuracy"]["overall_accuracy"]
    latency = results["latency"]["average_ms"]
    size_kb = results["model_size"]["size_kb"]
    
    print(f"\nüéä –í–ò–°–ù–û–í–ö–ò:")
    print("=" * 30)
    
    if accuracy >= 70:
        print("‚úÖ –í—ñ–¥–º—ñ–Ω–Ω–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å!")
    elif accuracy >= 50:
        print("üü° –ü—Ä–∏–π–Ω—è—Ç–Ω–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å")
    else:
        print("üî¥ –ù–∏–∑—å–∫–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å, –ø–æ—Ç—Ä—ñ–±–Ω–µ –¥–æ–¥–∞—Ç–∫–æ–≤–µ –Ω–∞–≤—á–∞–Ω–Ω—è")
    
    if latency <= 50:
        print("‚úÖ –®–≤–∏–¥–∫–∏–π —ñ–Ω—Ñ–µ—Ä–µ–Ω—Å!")
    elif latency <= 100:
        print("üü° –ü–æ–º—ñ—Ä–Ω–∞ —à–≤–∏–¥–∫—ñ—Å—Ç—å")
    else:
        print("üî¥ –ü–æ–≤—ñ–ª—å–Ω–∏–π —ñ–Ω—Ñ–µ—Ä–µ–Ω—Å")
        
    if size_kb <= 1000:
        print("‚úÖ –ö–æ–º–ø–∞–∫—Ç–Ω–∞ –º–æ–¥–µ–ª—å!")
    else:
        print("üü° –í–µ–ª–∏–∫–∞ –º–æ–¥–µ–ª—å")
    
    print(f"\nüéØ –ü—ñ–¥—Å—É–º–∫–æ–≤—ñ –º–µ—Ç—Ä–∏–∫–∏:")
    print(f"   Accuracy: {accuracy:.1f}%")
    print(f"   Latency: {latency:.1f} –º—Å") 
    print(f"   Size: {size_kb:.0f} KB")
    
    return results

if __name__ == "__main__":
    try:
        results = main()
        print(f"\n‚úÖ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ!")
        
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è: {e}")
        import traceback
        traceback.print_exc()