"""
Flask API –¥–ª—è —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –≥–æ–ª–æ—Å–æ–≤–∏—Ö –∫–æ–º–∞–Ω–¥
REST API endpoints –¥–ª—è —ñ–Ω—Ñ–µ—Ä–µ–Ω—Å—É –º–æ–¥–µ–ª—ñ
"""

from flask import Flask, request, jsonify
import torch
import torch.nn.functional as F
import numpy as np
import soundfile as sf
import io
import time
import os
import sys
import tempfile

# –î–æ–¥–∞—î–º–æ —à–ª—è—Ö –¥–æ –º–æ–¥—É–ª—ñ–≤
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from src.model import SimpleCNN, EvenSimplerCNN
from src.simple_data_loader import SimpleAudioPreprocessor

app = Flask(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω—ñ –∑–º—ñ–Ω–Ω—ñ –¥–ª—è –º–æ–¥–µ–ª—ñ
model = None
preprocessor = None
classes = ['yes', 'no', 'up', 'down']
device = torch.device('cpu')

def load_model(model_path='./models/best_model_simple.pth', model_type='simple'):
    """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –Ω–∞–≤—á–µ–Ω—É –º–æ–¥–µ–ª—å"""
    global model, preprocessor
    
    print(f"üîÑ –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –º–æ–¥–µ–ª—å –∑ {model_path}...")
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä—É –º–æ–¥–µ–ª—ñ
    if model_type == 'simple':
        model = SimpleCNN(num_classes=4)
    else:
        model = EvenSimplerCNN(num_classes=4)
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –≤–∞–≥–∏
    if os.path.exists(model_path):
        model.load_state_dict(torch.load(model_path, map_location=device))
        model.eval()
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ!")
    else:
        print(f"‚ö†Ô∏è –§–∞–π–ª –º–æ–¥–µ–ª—ñ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {model_path}")
        print("üîÑ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –Ω–µ–Ω–∞—á–µ–Ω—É –º–æ–¥–µ–ª—å (–≤–∏–ø–∞–¥–∫–æ–≤—ñ –≤–∞–≥–∏)")
        model.eval()
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å–æ—Ä
    preprocessor = SimpleAudioPreprocessor()
    
    return True

def predict_audio(audio_data, sample_rate=16000):
    """
    –†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –≥–æ–ª–æ—Å–æ–≤–æ—ó –∫–æ–º–∞–Ω–¥–∏ –∑ –∞—É–¥—ñ–æ
    
    Args:
        audio_data: numpy array –∑ –∞—É–¥—ñ–æ —Å–∏–≥–Ω–∞–ª–æ–º
        sample_rate: —á–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü—ñ—ó
        
    Returns:
        dict –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø—Ä–æ–≥–Ω–æ–∑—É
    """
    global model, preprocessor
    
    if model is None or preprocessor is None:
        return {"error": "–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞"}
    
    start_time = time.time()
    
    try:
        # –ü–µ—Ä–µ—Ç–≤–æ—Ä—é—î–º–æ –≤ tensor
        if len(audio_data.shape) == 1:
            audio_tensor = torch.from_numpy(audio_data[np.newaxis, :]).float()
        else:
            audio_tensor = torch.from_numpy(audio_data).float()
        
        # –ó–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ preprocessing
        processed_audio = preprocessor(audio_tensor)
        
        # –î–æ–¥–∞—î–º–æ batch dimension
        if len(processed_audio.shape) == 3:
            processed_audio = processed_audio.unsqueeze(0)
        
        # –ü—Ä–æ–≥–Ω–æ–∑
        with torch.no_grad():
            output = model(processed_audio)
            probabilities = F.softmax(output, dim=1)
            
            # –ù–∞–π–∫—Ä–∞—â–∞ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è
            _, predicted_idx = torch.max(output, 1)
            predicted_class = classes[predicted_idx.item()]
            confidence = probabilities[0][predicted_idx].item()
        
        # –£—Å—ñ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ
        all_probabilities = {
            classes[i]: float(probabilities[0][i]) 
            for i in range(len(classes))
        }
        
        inference_time = (time.time() - start_time) * 1000  # –º—ñ–ª—ñ—Å–µ–∫—É–Ω–¥–∏
        
        return {
            "predicted_class": predicted_class,
            "confidence": confidence,
            "all_probabilities": all_probabilities,
            "inference_time_ms": inference_time,
            "status": "success"
        }
        
    except Exception as e:
        return {
            "error": str(e),
            "status": "error"
        }

@app.route('/')
def home():
    """–ì–æ–ª–æ–≤–Ω–∞ —Å—Ç–æ—Ä—ñ–Ω–∫–∞ API"""
    return jsonify({
        "message": "Speech Commands Recognition API",
        "version": "1.0",
        "endpoints": {
            "/predict": "POST - –†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –∑ –∞—É–¥—ñ–æ —Ñ–∞–π–ª—É",
            "/predict_text": "POST - –¢–µ—Å—Ç–æ–≤–∏–π –ø—Ä–æ–≥–Ω–æ–∑ –∑ —Ç–µ–∫—Å—Ç—É",
            "/health": "GET - –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Å—Ç–∞–Ω—É API",
            "/classes": "GET - –°–ø–∏—Å–æ–∫ –ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω–∏—Ö –∫–ª–∞—Å—ñ–≤"
        },
        "classes": classes,
        "status": "running"
    })

@app.route('/health')
def health():
    """–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Å—Ç–∞–Ω—É API"""
    model_loaded = model is not None
    return jsonify({
        "status": "healthy" if model_loaded else "model_not_loaded",
        "model_loaded": model_loaded,
        "classes": classes,
        "device": str(device)
    })

@app.route('/classes')
def get_classes():
    """–û—Ç—Ä–∏–º–∞—Ç–∏ —Å–ø–∏—Å–æ–∫ –ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω–∏—Ö –∫–ª–∞—Å—ñ–≤"""
    return jsonify({
        "classes": classes,
        "count": len(classes)
    })

@app.route('/predict', methods=['POST'])
def predict():
    """
    –†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –≥–æ–ª–æ—Å–æ–≤–æ—ó –∫–æ–º–∞–Ω–¥–∏ –∑ –∞—É–¥—ñ–æ —Ñ–∞–π–ª—É
    
    –û—á—ñ–∫—É—î multipart/form-data –∑ —Ñ–∞–π–ª–æ–º 'audio'
    –ü—ñ–¥—Ç—Ä–∏–º—É—î —Ñ–æ—Ä–º–∞—Ç–∏: .wav, .mp3, .flac
    """
    
    if 'audio' not in request.files:
        return jsonify({
            "error": "–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∞—É–¥—ñ–æ —Ñ–∞–π–ª. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –ø–æ–ª–µ 'audio'",
            "status": "error"
        }), 400
    
    audio_file = request.files['audio']
    
    if audio_file.filename == '':
        return jsonify({
            "error": "–§–∞–π–ª –Ω–µ –≤–∏–±—Ä–∞–Ω–æ",
            "status": "error"
        }), 400
    
    try:
        # –ß–∏—Ç–∞—î–º–æ –∞—É–¥—ñ–æ –Ω–∞–ø—Ä—è–º—É –∑ –ø–∞–º'—è—Ç—ñ
        audio_file.seek(0)  # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ—Å—è –Ω–∞ –ø–æ—á–∞—Ç–æ–∫ —Ñ–∞–π–ª—É
        audio_data, sample_rate = sf.read(io.BytesIO(audio_file.read()))
        
        # –†–æ–∑–ø—ñ–∑–Ω–∞—î–º–æ
        result = predict_audio(audio_data, sample_rate)
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({
            "error": f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ –∞—É–¥—ñ–æ: {str(e)}",
            "status": "error"
        }), 500

@app.route('/predict_text', methods=['POST'])
def predict_text():
    """
    –¢–µ—Å—Ç–æ–≤–∏–π endpoint –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑—É –∑ —Ç–µ–∫—Å—Ç—É
    –°–∏–º—É–ª—é—î —Ä–æ–±–æ—Ç—É API –±–µ–∑ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∞—É–¥—ñ–æ
    """
    
    data = request.get_json()
    
    if not data or 'text' not in data:
        return jsonify({
            "error": "–ü–æ—Ç—Ä—ñ–±–µ–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä 'text' –≤ JSON",
            "status": "error"
        }), 400
    
    text = data['text'].lower().strip()
    
    # –ü—Ä–æ—Å—Ç–∞ —Å–∏–º—É–ª—è—Ü—ñ—è: —è–∫—â–æ —Ç–µ–∫—Å—Ç –º—ñ—Å—Ç–∏—Ç—å –æ–¥–Ω—É –∑ –∫–æ–º–∞–Ω–¥
    predicted_class = "unknown"
    confidence = 0.25  # –ë–∞–∑–æ–≤–∞ –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å
    
    for class_name in classes:
        if class_name in text:
            predicted_class = class_name
            confidence = 0.85 + np.random.random() * 0.1  # 85-95%
            break
    
    # –ì–µ–Ω–µ—Ä—É—î–º–æ —Ä–µ–∞–ª—ñ—Å—Ç–∏—á–Ω—ñ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ
    all_probabilities = {}
    remaining_prob = 1.0 - confidence
    
    for i, class_name in enumerate(classes):
        if class_name == predicted_class:
            all_probabilities[class_name] = confidence
        else:
            # –†–æ–∑–ø–æ–¥—ñ–ª—è—î–º–æ —Ä–µ—à—Ç—É –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ
            prob = remaining_prob / (len(classes) - 1)
            prob += np.random.random() * 0.05  # –¢—Ä–æ—Ö–∏ —Ä–∞–Ω–¥–æ–º–Ω–æ—Å—Ç—ñ
            all_probabilities[class_name] = min(prob, remaining_prob)
    
    # –ù–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ —â–æ–± —Å—É–º–∞ –±—É–ª–∞ 1.0
    total = sum(all_probabilities.values())
    all_probabilities = {k: v/total for k, v in all_probabilities.items()}
    
    return jsonify({
        "predicted_class": predicted_class,
        "confidence": confidence,
        "all_probabilities": all_probabilities,
        "inference_time_ms": np.random.uniform(5, 25),  # –°–∏–º—É–ª—è—Ü—ñ—è —á–∞—Å—É
        "input_text": text,
        "status": "success (simulation)"
    })

@app.errorhandler(404)
def not_found(error):
    """–û–±—Ä–æ–±–∫–∞ 404 –ø–æ–º–∏–ª–æ–∫"""
    return jsonify({
        "error": "Endpoint –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ",
        "available_endpoints": ["/", "/health", "/classes", "/predict", "/predict_text"],
        "status": "error"
    }), 404

@app.errorhandler(500)
def internal_error(error):
    """–û–±—Ä–æ–±–∫–∞ –≤–Ω—É—Ç—Ä—ñ—à–Ω—ñ—Ö –ø–æ–º–∏–ª–æ–∫"""
    return jsonify({
        "error": "–í–Ω—É—Ç—Ä—ñ—à–Ω—è –ø–æ–º–∏–ª–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞",
        "status": "error"
    }), 500

if __name__ == '__main__':
    print("üöÄ –ó–∞–ø—É—Å–∫–∞—î–º–æ Flask API –¥–ª—è —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –≥–æ–ª–æ—Å–æ–≤–∏—Ö –∫–æ–º–∞–Ω–¥")
    print("=" * 60)
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –º–æ–¥–µ–ª—å
    load_model()
    
    print(f"\nüì° API endpoints:")
    print(f"   GET  /           - –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ API")
    print(f"   GET  /health     - –°—Ç–∞–Ω –∑–¥–æ—Ä–æ–≤'—è")
    print(f"   GET  /classes    - –ü—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω—ñ –∫–ª–∞—Å–∏") 
    print(f"   POST /predict    - –†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –∞—É–¥—ñ–æ —Ñ–∞–π–ª—É")
    print(f"   POST /predict_text - –¢–µ—Å—Ç–æ–≤–∏–π –ø—Ä–æ–≥–Ω–æ–∑")
    
    print(f"\nüéØ –ü—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω—ñ –∫–æ–º–∞–Ω–¥–∏: {', '.join(classes)}")
    
    print(f"\nüî• –ó–∞–ø—É—Å–∫–∞—î–º–æ —Å–µ—Ä–≤–µ—Ä –Ω–∞ http://localhost:5000")
    print("üí° –ù–∞—Ç–∏—Å–Ω–∏ Ctrl+C –¥–ª—è –∑—É–ø–∏–Ω–∫–∏")
    
    # –ó–∞–ø—É—Å–∫–∞—î–º–æ Flask —Å–µ—Ä–≤–µ—Ä
    app.run(
        host='0.0.0.0',     # –î–æ—Å—Ç—É–ø –∑ –±—É–¥—å-—è–∫–æ—ó IP
        port=5000,          # –ü–æ—Ä—Ç
        debug=True,         # –†–µ–∂–∏–º —Ä–æ–∑—Ä–æ–±–∫–∏
        use_reloader=False  # –ù–µ –ø–µ—Ä–µ–∑–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ (—â–æ–± –Ω–µ –∫–æ–Ω—Ñ–ª—ñ–∫—Ç—É–≤–∞—Ç–∏ –∑ –Ω–∞–≤—á–∞–Ω–Ω—è–º)
    )